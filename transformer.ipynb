{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"torch==2.2.1\" \"transformers==4.41.2\" \"datasets==2.20.0\"\n"
      ],
      "metadata": {
        "id": "P7ojr3V2Du0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "ds = load_dataset(\"BALM/BALM-benchmark\", \"BindingDB_filtered\", split=\"train\")\n",
        "df = ds.to_pandas()\n",
        "df_5k = df.sample(n=5000, random_state=42)\n",
        "df_5k.to_csv(\"bindingdb_5000.csv\", index=False)\n",
        "df_5k.head(), df_5k.shape"
      ],
      "metadata": {
        "id": "x-oE1k34D03P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, RobertaModel\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "df = pd.read_csv(\"bindingdb_5000.csv\")\n",
        "\n",
        "drug_model_name = \"DeepChem/ChemBERTa-77M-MTR\"\n",
        "MAX_LEN = 256\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(drug_model_name)\n",
        "backbone = RobertaModel.from_pretrained(drug_model_name)\n",
        "\n",
        "for p in backbone.parameters():\n",
        "    p.requires_grad = False  # نثبّت الباكبون\n",
        "\n",
        "H = backbone.config.hidden_size\n",
        "head = nn.Sequential(\n",
        "    nn.Linear(H, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 1),\n",
        ")\n",
        "\n",
        "backbone.to(device)\n",
        "head.to(device)\n",
        "\n",
        "class BindingDB5000(Dataset):\n",
        "    def __init__(self, frame):\n",
        "        self.df = frame.reset_index(drop=True)\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        return str(row[\"Drug\"])[:MAX_LEN], torch.tensor(row[\"Y\"], dtype=torch.float32)\n",
        "\n",
        "dataset = BindingDB5000(df)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "mse = nn.MSELoss()\n",
        "def scale_labels(y):\n",
        "    return (y - 6.0) / 4.0  # من 2..10 إلى -1..1 تقريباً\n",
        "\n",
        "optimizer = torch.optim.AdamW(head.parameters(), lr=1e-3)\n",
        "EPOCHS = 3\n",
        "\n",
        "backbone.eval()\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss, n = 0.0, 0\n",
        "    for drug_seq, y in loader:\n",
        "        optimizer.zero_grad()\n",
        "        y = y.to(device)\n",
        "        y_scaled = scale_labels(y)\n",
        "\n",
        "        tok = tokenizer(\n",
        "            list(drug_seq),\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = backbone(**tok).last_hidden_state[:, 0, :]\n",
        "        pred = head(out).squeeze(-1)\n",
        "\n",
        "        loss = mse(pred, y_scaled)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bs = y.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        n += bs\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} loss={total_loss/n:.4f}\")"
      ],
      "metadata": {
        "id": "09aDb3kKEnz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) تحميل الداتا\n",
        "df = pd.read_csv(\"bindingdb_10000.csv\")\n",
        "\n",
        "# لو العمود Y هو بالفعل pKd (قيم بين 2 و 10) استخدمه مباشرة\n",
        "print(df[\"Y\"].min(), df[\"Y\"].max())\n",
        "\n",
        "# 2) رسم الهستوجرام\n",
        "plt.figure(figsize=(6,4), dpi=150)\n",
        "plt.hist(df[\"Y\"], bins=30, color=\"#4C72B0\", edgecolor=\"black\", alpha=0.8)\n",
        "plt.xlabel(\"pKd\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of pKd values in the BindingDB-derived dataset\")\n",
        "plt.grid(axis=\"y\", alpha=0.2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figure2_pKd_distribution.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qmxsj3O1E0nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmxsjO1E0nb"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) تحميل الداتا\n",
        "df = pd.read_csv(\"bindingdb_5000.csv\") # Corrected filename\n",
        "\n",
        "# لو العمود Y هو بالفعل pKd (قيم بين 2 و 10) استخدمه مباشرة\n",
        "print(df[\"Y\"].min(), df[\"Y\"].max())\n",
        "\n",
        "# 2) رسم الهستوجرام\n",
        "plt.figure(figsize=(6,4), dpi=150)\n",
        "plt.hist(df[\"Y\"], bins=30, color=\"#4C72B0\", edgecolor=\"black\", alpha=0.8)\n",
        "plt.xlabel(\"pKd\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of pKd values in the BindingDB-derived dataset\")\n",
        "plt.grid(axis=\"y\", alpha=0.2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figure2_pKd_distribution.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "save_dir = Path(\"chemberta_bindingdb_5k\")\n",
        "save_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# حفظ رأس الـ regression فقط (head)\n",
        "torch.save(head.state_dict(), save_dir / \"head.pt\")\n",
        "\n",
        "# حفظ إعدادات الموديل والتوكنيزر لإعادة الاستخدام\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "backbone.save_pretrained(save_dir)\n",
        "\n",
        "print(\"Saved to\", save_dir)\n"
      ],
      "metadata": {
        "id": "oPa_-KljE_zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "df = pd.read_csv(\"bindingdb_5000.csv\").reset_index(drop=True)\n",
        "\n",
        "def scale_labels(y):\n",
        "    return (y - 6.0) / 4.0\n",
        "\n",
        "def inverse_scale(y_scaled):\n",
        "    return y_scaled * 4.0 + 6.0\n",
        "\n",
        "backbone.eval()\n",
        "head.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(5):\n",
        "        drug = str(df.loc[i, \"Drug\"])[:256]\n",
        "        y_true = df.loc[i, \"Y\"]\n",
        "\n",
        "        tok = tokenizer(\n",
        "            [drug],\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=256,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(device)\n",
        "\n",
        "        out = backbone(**tok).last_hidden_state[:, 0, :]\n",
        "        y_pred_scaled = head(out).squeeze(-1)\n",
        "        y_pred = inverse_scale(y_pred_scaled).item()\n",
        "\n",
        "        print(f\"Example {i}: true={y_true:.3f}, pred={y_pred:.3f}\")\n"
      ],
      "metadata": {
        "id": "XWnWdmBMFEc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "df = pd.read_csv(\"bindingdb_5000.csv\").reset_index(drop=True)\n",
        "\n",
        "def scale_labels(y):\n",
        "    return (y - 6.0) / 4.0\n",
        "\n",
        "def inverse_scale(y_scaled):\n",
        "    return y_scaled * 4.0 + 6.0\n",
        "\n",
        "backbone.eval()\n",
        "head.eval()\n",
        "\n",
        "rows = []\n",
        "with torch.no_grad():\n",
        "    for i in range(20):  # أول 20 مثال، غيّر الرقم لو عايز أكتر\n",
        "        drug = str(df.loc[i, \"Drug\"])[:256]\n",
        "        target = str(df.loc[i, \"Target\"])[:60] + \"...\"\n",
        "        y_true = df.loc[i, \"Y\"]\n",
        "\n",
        "        tok = tokenizer(\n",
        "            [drug],\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=256,\n",
        "            return_tensors=\"pt\",\n",
        "        ).to(device)\n",
        "\n",
        "        out = backbone(**tok).last_hidden_state[:, 0, :]\n",
        "        y_pred_scaled = head(out).squeeze(-1)\n",
        "        y_pred = inverse_scale(y_pred_scaled).item()\n",
        "\n",
        "        rows.append({\n",
        "            \"Drug_ID\": df.loc[i, \"Drug_ID\"],\n",
        "            \"Target_ID\": df.loc[i, \"Target_ID\"],\n",
        "            \"Target_seq_head\": target,\n",
        "            \"Affinity_true\": round(y_true, 3),\n",
        "            \"Affinity_pred\": round(y_pred, 3),\n",
        "        })\n",
        "\n",
        "result_df = pd.DataFrame(rows)\n",
        "result_df\n"
      ],
      "metadata": {
        "id": "K8zSzD7sFJD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push\n"
      ],
      "metadata": {
        "id": "S0kHu8VhImqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "id": "GfPWJzjtI3vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Abdulazim2/Predicting-Drug-Target-Binding-Affinity.git\n"
      ],
      "metadata": {
        "id": "Eh1e7YXaJGzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Predicting-Drug-Target-Binding-Affinity\n"
      ],
      "metadata": {
        "id": "-0LNbEEeJLE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a\n"
      ],
      "metadata": {
        "id": "LnQBEQ9sJPWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/trins.ipynb .\n"
      ],
      "metadata": {
        "id": "BU4ndlzvJWAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "id": "Enh6_iZZJjNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content -name \"*.ipynb\"\n"
      ],
      "metadata": {
        "id": "Xv4yiGRXJmpD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE37z9QvN9T2"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install datasets numpy pandas scikit-learn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "T-L6NebCOTw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"BALM/BALM-benchmark\", \"BindingDB_filtered\")\n",
        "data = dataset[\"train\"]\n",
        "print(\"Sample:\", data[0])"
      ],
      "metadata": {
        "id": "w8y_aq9mOanU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"BALM/BALM-benchmark\", \"BindingDB_filtered\")\n",
        "data = dataset[\"train\"]\n",
        "print(\"Sample:\", data[0])"
      ],
      "metadata": {
        "id": "5kycRCOSOqMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789=#()%+-[]@\")\n",
        "char2idx = {c:i+1 for i,c in enumerate(chars)}\n",
        "\n",
        "def encode(seq, max_len):\n",
        "    encoded = [char2idx.get(c, 0) for c in seq[:max_len]]\n",
        "    return encoded + [0]*(max_len - len(encoded))"
      ],
      "metadata": {
        "id": "rWOJTcw8Ot9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class BALMDataset(Dataset):\n",
        "    def __init__(self, data, drug_max=100, target_max=1000):\n",
        "        self.data = data\n",
        "        self.drug_max = drug_max\n",
        "        self.target_max = target_max\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        d = self.data[idx]\n",
        "        drug = torch.tensor(encode(d[\"Drug\"], self.drug_max))\n",
        "        target = torch.tensor(encode(d[\"Target\"], self.target_max))\n",
        "        y = torch.tensor(d[\"Y\"], dtype=torch.float)\n",
        "        return drug, target, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "_yvCMEYHOzLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "all_data = list(data)\n",
        "\n",
        "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = BALMDataset(train_data)\n",
        "test_dataset = BALMDataset(test_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "print(\"Train size:\", len(train_dataset))\n",
        "print(\"Test size:\", len(test_dataset))\n"
      ],
      "metadata": {
        "id": "XVhJfSx4O5EH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size=100, embed_dim=128, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim*2, 1)\n",
        "\n",
        "    def forward(self, drug, target):\n",
        "        d = self.embed(drug)\n",
        "        t = self.embed(target)\n",
        "\n",
        "        _, (d_h, _) = self.lstm(d)\n",
        "        _, (t_h, _) = self.lstm(t)\n",
        "\n",
        "        x = torch.cat([d_h[-1], t_h[-1]], dim=1)\n",
        "        return self.fc(x).squeeze()\n",
        "\n",
        "model = RNNModel().to(device)\n"
      ],
      "metadata": {
        "id": "0HUmyFgUPBJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data loading and preprocessing\n",
        "dataset = load_dataset(\"BALM/BALM-benchmark\", \"BindingDB_filtered\")\n",
        "data = dataset[\"train\"]\n",
        "\n",
        "chars = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789=#()%+-[]@\")\n",
        "char2idx = {c:i+1 for i,c in enumerate(chars)}\n",
        "\n",
        "def encode(seq, max_len):\n",
        "    encoded = [char2idx.get(c, 0) for c in seq[:max_len]]\n",
        "    return encoded + [0]*(max_len - len(encoded))\n",
        "\n",
        "class BALMDataset(Dataset):\n",
        "    def __init__(self, data, drug_max=100, target_max=1000):\n",
        "        self.data = data\n",
        "        self.drug_max = drug_max\n",
        "        self.target_max = target_max\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        d = self.data[idx]\n",
        "        drug = torch.tensor(encode(d[\"Drug\"], self.drug_max))\n",
        "        target = torch.tensor(encode(d[\"Target\"], self.target_max))\n",
        "        y = torch.tensor(d[\"Y\"], dtype=torch.float)\n",
        "        return drug, target, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "all_data = list(data)\n",
        "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = BALMDataset(train_data)\n",
        "test_dataset = BALMDataset(test_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# RNNModel class definition\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size=100, embed_dim=128, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim*2, 1)\n",
        "\n",
        "    def forward(self, drug, target):\n",
        "        d = self.embed(drug)\n",
        "        t = self.embed(target)\n",
        "\n",
        "        _, (d_h, _) = self.lstm(d)\n",
        "        _, (t_h, _) = self.lstm(t)\n",
        "\n",
        "        x = torch.cat([d_h[-1], t_h[-1]], dim=1)\n",
        "        return self.fc(x).squeeze()\n",
        "\n",
        "# Model instantiation\n",
        "model = RNNModel().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for drug, target, y in train_loader:\n",
        "        drug, target, y = drug.to(device), target.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(drug, target)\n",
        "        loss = loss_fn(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "b3XLJYtgPFeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds, targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for drug, target, y in test_loader:\n",
        "        drug, target, y = drug.to(device), target.to(device), y.to(device)\n",
        "        pred = model(drug, target)\n",
        "        preds.extend(pred.cpu().numpy())\n",
        "        targets.extend(y.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "nJwV77S6PP0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "mse = mean_squared_error(targets, preds)\n",
        "mae = mean_absolute_error(targets, preds)\n",
        "print(f\"Test MSE: {mse:.4f}, Test MAE: {mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "jQ9sa6nmQmTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(targets, preds, alpha=0.5)\n",
        "plt.xlabel(\"True Y\")\n",
        "plt.ylabel(\"Predicted Y\")\n",
        "plt.title(\"RNN Predictions vs True Values\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cr2zeQOgQpsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"True Y vs Predicted Y for first 10 samples:\")\n",
        "for i in range(10):\n",
        "    print(f\"Sample {i+1}: True = {targets[i]:.4f}, Predicted = {preds[i]:.4f}\")\n"
      ],
      "metadata": {
        "id": "7kFBL_mtQxFR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}